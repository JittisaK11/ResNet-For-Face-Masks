import torch
import torch.nn as nn
import torch.optim as optim
import cv2
import numpy as np
import os
import random
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from tqdm import tqdm

MASK_DIR = '/Users/14829/Desktop/DATA/experiements/data/with_mask'
NOMASK_DIR = '/Users/14829/Desktop/DATA/experiements/data/without_mask'

os.chdir(MASK_DIR)

torch.set_grad_enabled(True)

#Download 680 Mask Images

mask_data = []
for img in tqdm(os.listdir(MASK_DIR)):
    try:
        path=os.path.join(MASK_DIR,img)
        img=cv2.imread(path)
        img=cv2.resize(img, (28,28))
        img = torch.from_numpy(img)
        img = img.permute(2,0,1)
        label = [1]
        mask_data.append([img, label])
    except Exception as e:
        print(str(e))
  
# Split Mask Images into 0.8x680 train and 0.2x680 test sets
mask_train = mask_data[0:544]
mask_test = mask_data[544:]

nonmask_data = []
for img in tqdm(os.listdir(NOMASK_DIR)):
    try:
        path=os.path.join(NOMASK_DIR,img)
        img=cv2.imread(path)
        img=cv2.resize(img, (28,28))
        img = torch.from_numpy(img)
        img = img.permute(2,0,1)
        label = [0]
        nonmask_data.append([img, label])
    except Exception as e:
        print(str(e))
        
nonmask_train = nonmask_data[0:544]
nonmask_test = nonmask_data[544:]

train_data = nonmask_train + mask_train
random.shuffle(train_data)

test_data = nonmask_test + mask_test
random.shuffle(test_data)

def get_num_correct(pred, labels):
  return pred.argmax(dim=1).eq(labels).sum().item()
  
class block(nn.Module):
    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):
        super(block, self).__init__()
        self.expansion = 4
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.conv3 = nn.Conv2d(out_channels, out_channels*4, kernel_size=1, stride=1, padding=0)
        self.bn3 = nn.BatchNorm2d(out_channels*4)
        nn.BatchNorm2d(out_channels*4)
        self.relu = nn.ReLU()
        self.identity_downsample = identity_downsample
        
    def forward(self, x):
        identity = x
        
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu(x)
        x = self.conv3(x)
        x = self.bn3(x)
        x = self.relu(x)
        
        if self.identity_downsample is not None:
            identity = self.identity_downsample(identity)
        x += identity
        x = self.relu(x)
        return x

        
class ResNet(nn.Module): # [3, 4, 6, 3]
    def __init__(self, block, layers, image_channels, num_classes):
        super(ResNet, self).__init__()
        self.in_channels = 64
        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU()
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        
        #ResNet layers
        self.layer1 = self.make_layer(block, layers[0], out_channels=64, stride=1)
        self.layer2 = self.make_layer(block, layers[1], out_channels=128, stride=2)
        self.layer3 = self.make_layer(block, layers[2], out_channels=256, stride=2)
        self.layer4 = self.make_layer(block, layers[3], out_channels=512, stride=2)
        
        self.avgpool = nn.AdaptiveAvgPool2d((1,1))
        self.fc = nn.Linear(512*4, num_classes)
    def forward(self, x):
        x = self.conv1(x.float())
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        
        x = self.avgpool(x)
        x = x.reshape(x.shape[0], -1)
        x = self.fc(x)
        
        return x
        
        
        
    def make_layer(self, block, num_res_blocks, out_channels, stride):
        identity_downsample = None
        layers = []
        
        if stride != 1 or self.in_channels != out_channels*4:
            identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, out_channels*4, kernel_size=1, stride=stride), 
                                                nn.BatchNorm2d(out_channels*4))
            
        layers.append(block(self.in_channels, out_channels, identity_downsample, stride))
        self.in_channels = out_channels*4 
        
        for i in range(num_res_blocks - 1):
            layers.append(block(self.in_channels, out_channels))
        return nn.Sequential(*layers)

def ResNet50(img_channels=3, num_classes=2):
    return ResNet(block, [3,4,6,3], img_channels, num_classes)
    
net = ResNet50()

train_loader = torch.utils.data.DataLoader(train_data, batch_size=64)
optimizer = optim.Adam(net.parameters(), lr=0.01) # network.parameters() are the network's weights



for epoch in range(5):

  total_loss = 0
  total_correct = 0
  
  for batch in train_loader: 
    images, labels = batch

    optimizer.zero_grad()
    preds = net(images) 
    loss = F.cross_entropy(preds, labels[0])

    loss.backward()
    optimizer.step()

    total_loss += loss.item()
    total_correct += get_num_correct(preds, labels[0])

  print("epoch:", epoch, "total_correct", total_correct, "loss:", total_loss)
  
test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)
test_batch = next(iter(test_loader))
test_images, test_labels = test_batch

test_preds = net(test_images)
test_num_correct = test_preds.argmax(dim=1).eq(test_labels[0]).sum().item()
print('accuracy: ', test_num_correct/100)

fun_image=cv2.imread('/Users/14829/Desktop/Jane.jpg')
img=cv2.resize(fun_image, (28,28))

plt.imshow(img)
plt.show

img = torch.from_numpy(img)
img = img.unsqueeze(0)
img = img.permute(0,3,1,2)

net.eval()
 
